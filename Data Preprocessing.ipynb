{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnHrwznsei4J"
      },
      "outputs": [],
      "source": [
        "#importing all necessary modules\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "import math\n",
        "import time\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.exc import GeocoderTimedOut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVXkezjSro--"
      },
      "outputs": [],
      "source": [
        "#1: selecting relevant features\n",
        "\n",
        "master = [] #Initialize list to store the relevant data in\n",
        "\n",
        "# List of files to be processed\n",
        "files = [\"19901999.csv\", \"20002012.csv\", \"20122014.csv\", \"20152016.csv\", \"2017onwards.csv\"]\n",
        "\n",
        "# Adds information for files in the first 4 sets. Last set has different indexing\n",
        "for filename in files[:-1]:\n",
        "  with open('Datasets/' + filename, 'r') as f:\n",
        "    header = next(f)\n",
        "    for row in f:\n",
        "      lis = row.strip().split(',')\n",
        "      lis[0] = lis[0][0:4] + lis[0][5:] #processing string with '-' into an integer value\n",
        "      line = [float(lis[0]), lis[2], float(lis[6]), lis[7], float(lis[8]), float(lis[9])] #referencing relevent features and adding them\n",
        "      line[3] = line[3].upper()\n",
        "      master.append(line)\n",
        "\n",
        "#Adds information for files in the last set\n",
        "with open('Datasets/' + files[-1], 'r') as f:\n",
        "  header = next(f)\n",
        "  for row in f:\n",
        "    lis = row.strip().split(',')\n",
        "    lis[0] = lis[0][0:4] + lis[0][5:] #processing string with '-' into an integer value\n",
        "    line = [float(lis[0]), lis[2], float(lis[6]), lis[7], float(lis[8]), float(lis[10])] #referencing relevent features and adding them\n",
        "    line[3] = line[3].upper()\n",
        "    master.append(line)\n",
        "\n",
        "#Ignores data past 2020 \n",
        "master = master[:810459]\n",
        "\n",
        "#initialize values for better and more intuitive referencing of indexes with minimal confusion\n",
        "month, flat_type, floor_area_sqm, flat_model, lease_commence_date, resale_price, unemployment_rate, real_gdp, distance_from_cbd, population_size = 0,1,2,3,4,5,6,7,8,9\n",
        "\n",
        "#2: encoding categorical values for flat_model and flat_type\n",
        "enc = OrdinalEncoder()\n",
        "X = [['1 ROOM'], ['2 ROOM'], ['3 ROOM'], ['4 ROOM'], ['5 ROOM'], ['EXECUTIVE'], ['MULTI-GENERATION'], ['MULTI GENERATION']]\n",
        "X_2 = [['SIMPLIFIED'], ['IMPROVED'], ['MODEL A'], ['APARTMENT'], ['NEW GENERATION'], ['STANDARD'], ['MAISONETTE'], ['MODEL A-MAISONETTE'], ['TERRACE'], ['IMPROVED-MAISONETTE'], ['PREMIUM APARTMENT'], ['MULTI GENERATION'], ['2-ROOM'], ['MODEL A2'], ['PREMIUM MAISONETTE'], ['ADJOINED FLAT'], ['TYPE S1'], ['DBSS'], ['PREMIUM APARTMENT LOFT'], ['TYPE S2'], ['3GEN']]\n",
        "\n",
        "enc.fit(X)\n",
        "result = enc.transform([[row[flat_type]] for row in master]) #flat type encoding\n",
        "enc.fit(X_2)\n",
        "result2 = enc.transform([[row[flat_model]] for row in master]) #flat model encoding\n",
        "\n",
        "for row in range(len(master)):\n",
        "  master[row][flat_type] = result[row][0]\n",
        "  master[row][flat_model] = result2[row][0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csmWggQ7ASR-"
      },
      "outputs": [],
      "source": [
        "#3: adding unemployment rate as a feature to the master dataset\n",
        "import csv\n",
        "#list of sublists seperated by quarters\n",
        "months = [['01', '02', '03'], ['04', '05', '06'], ['07', '08', '09'], ['10', '11', '12']]\n",
        "\n",
        "dic = {} #dic will store manually created string keys ('20241Q'...'19904Q') that will reference sublists consisting of months(from the months list) in that specific quarter.\n",
        "#eg. {'20241Q':['202401.0', '202402.0', '202403.0']}\n",
        "for i in range(1990, 2025):\n",
        "  for j in range(1, 5):\n",
        "    dic[str(i)+str(j)+'Q'] = []\n",
        "    for m in months[j-1]:\n",
        "      dic[str(i)+str(j)+'Q'] += [float(str(i)+m)]\n",
        "\n",
        "finaldic = {}\n",
        "\n",
        "with open('Datasets/UnemploymentRateEndOfPeriodQuarterlySeasonallyAdjusted.csv', 'r') as f:\n",
        "  masterr = [] #this list will contain 2 rows: row 1 contains the quarterly label year values such as '20241Q'. row 2 contains the unemployment rate for that quarter such as '1.7'\n",
        "  for row in f:\n",
        "    row = row.strip().split(',')\n",
        "    masterr.append(row[1:]) #removing the titles total unemployment rate, resident unemployment rate\n",
        "  masterr = masterr[:2] #removing resident and citize unemployment rate\n",
        "  masterr[1] = masterr[1][1:] #removing the title ' (SA)\"'\n",
        "\n",
        "#as the file only contains unemployment rates from 1992-2024,\n",
        "#through research(https://stats.mom.gov.sg/iMAS_Tables/Times%20Series%20Table/mrsd_14_Historical_Unemployment_Rate_28Jan21.xlsx)\n",
        "#we will be manually inserting unemployment rates as 1.7 for each quarter in 1990 and 1991.\n",
        "for i in range(1, 5):\n",
        "  masterr[0].append('1990'+str(i)+'Q')\n",
        "  masterr[0].append('1991'+str(i)+'Q')\n",
        "  masterr[1] += [1.7, 1.7]\n",
        "\n",
        "#for each quarter label in the first row, and for each key in dic, if they equate to each other,\n",
        "#we will insert into finaldic, (the values in the sublist that the key in dic refers to) as the key\n",
        "#that references the (unemployment rate for that month)value.\n",
        "for item in masterr[0]:\n",
        "  for row in dic:\n",
        "    if item == row:\n",
        "      for i in dic[row]:\n",
        "        finaldic[i] = float(masterr[1][masterr[0].index(item)])\n",
        "\n",
        "#adding the correct unemployment rate to the correct month in the dataset based on the float key of the month in finaldic\n",
        "for row in master:\n",
        "  for item in finaldic:\n",
        "    if row[month] == item:\n",
        "      row += [finaldic[item]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puUkwPvHAieI"
      },
      "outputs": [],
      "source": [
        "#4: calculating remaining lease by performing the following: 99 - (current year - lease commencement date)\n",
        "for row in master:\n",
        "  result = 99-(int(str(row[month])[:4])-int(str(row[lease_commence_date])[:4]))\n",
        "  row[lease_commence_date] = result\n",
        "\n",
        "remaining_lease = lease_commence_date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc3j5DffIeVZ",
        "outputId": "7ba7b79d-69b9-4635-978a-b8a2c33c9c45"
      },
      "outputs": [],
      "source": [
        "#5 inserting real gdp into the dataset\n",
        "with open('Datasets/M015651.csv', 'r') as f:\n",
        "  finalliz = f.readlines()\n",
        "  year = (finalliz[10].strip().split(','))[1:] #removing irrelevant data and the header value to obtain the years\n",
        "  r = year.index('1990 1Q ') #finding the index to cut off and obtain relevant years\n",
        "  year = year[:r+1]\n",
        "  gdp = (finalliz[11].strip().split(','))[1:] #removing irrelevant data and the header value to obtain the gdp\n",
        "  gdp = gdp[:r+1]\n",
        "\n",
        "for row in range(len(year)):\n",
        "  year[row] = year[row][:4] + year[row][5:7] #removing spaces from the quearterly year labels\n",
        "\n",
        "finalfinaldic = {}\n",
        "\n",
        "#for each quarter label in the year list, and for each key in dic, if they equate to each other,\n",
        "#we will insert into finalfinaldic, (the values in the sublist that the key in dic refers to) as the key\n",
        "#that references the (gdp)value in the gdp list.\n",
        "for item in year:\n",
        "  for row in dic:\n",
        "    if item == row:\n",
        "      for i in dic[row]:\n",
        "        finalfinaldic[i] = float(gdp[year.index(item)])\n",
        "\n",
        "#adding the correct unemployment rate to the correct month in the dataset based on the float key of the month in finaldic\n",
        "for row in master:\n",
        "  for item in finalfinaldic:\n",
        "    if row[month] == item:\n",
        "      row += [finalfinaldic[item]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fmKOTPtMNCDT",
        "outputId": "0871780b-a108-4e71-92f8-0b723997c0b9"
      },
      "outputs": [],
      "source": [
        "#6: inserting the distance to cbd\n",
        "\n",
        "#Initializes working data array\n",
        "data = []\n",
        "\n",
        "for filename in files:\n",
        "  with open(\"Datasets/\" + filename,'r') as f:\n",
        "    i = 0\n",
        "    for row in f:\n",
        "      if i != 0:\n",
        "        data.append(row.strip('\\n').split(','))\n",
        "      i += 1\n",
        "\n",
        "#Ignores data past 2020 \n",
        "master = master[:810459]\n",
        "\n",
        "def get_lat_lon(address):\n",
        "    \"\"\"\n",
        "    Gets the latitude and longitude of the street using Nominatim API\n",
        "    \"\"\"\n",
        "    #Initializes the geocoder and collects the location information\n",
        "    geolocator = Nominatim(user_agent=\"Jupyter_AI_Project_HomeBros\")\n",
        "    location = geolocator.geocode(address, timeout=10)\n",
        "\n",
        "    #Begins up to 5 attempts to find location, increasing delay time each attempt in case of timeout\n",
        "    for attempt in range(5):\n",
        "        delay = 1\n",
        "        try:\n",
        "            location = geolocator.geocode(address, timeout=10)\n",
        "\n",
        "            #Checks if location found. If not, prints address and returns None.\n",
        "            #When not found, address was examined to identify why. (During preprocessing. Resulted in the many if statements in the preprocessing function)\n",
        "            if location:\n",
        "                return location.latitude, location.longitude\n",
        "            else:\n",
        "                print(address)\n",
        "                return None, None\n",
        "\n",
        "        except GeocoderTimedOut:\n",
        "            print(f\"Timeout on attempt {attempt+1} for '{address}'... retrying in {delay}s.\")\n",
        "            time.sleep(delay)\n",
        "            delay += 1\n",
        "\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculates shortest distance to CBD in kilometres, accounting for the curve of the Earth\n",
        "    \"\"\"\n",
        "    R = 6371  # Earth's radius in kilometers\n",
        "    phi1 = math.radians(lat1)\n",
        "    phi2 = math.radians(lat2)\n",
        "    delta_phi = math.radians(lat2 - lat1)\n",
        "    delta_lambda = math.radians(lon2 - lon1)\n",
        "\n",
        "    a = math.sin(delta_phi/2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda/2)**2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "    distance = R * c\n",
        "    return round(distance,3)\n",
        "\n",
        "def preprocessing(data, streets, unique_streets):\n",
        "  \"\"\"\n",
        "  Handles shortforms and missing streets\n",
        "  \"\"\"\n",
        "  for row in data[1:]:\n",
        "    new_strt = row[4]\n",
        "\n",
        "    # Storage to retrieve indexes later\n",
        "    if new_strt not in streets:\n",
        "      streets.append(new_strt)\n",
        "\n",
        "    # Processing\n",
        "    if \" NTH \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" NTH \", \" NORTH \")\n",
        "    if \" NTH\" in new_strt:\n",
        "      new_strt = new_strt.replace(\" NTH\", \" NORTH\")\n",
        "    if \" STH \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" STH \", \" SOUTH \")\n",
        "    if \" ST \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" ST \", \" STREET \")\n",
        "    if \" RD \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" RD \", \" ROAD \")\n",
        "    if \"BT \" in new_strt:\n",
        "      new_strt = new_strt.replace(\"BT \", \"BUKIT \")\n",
        "    if \" BT \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" BT \", \" BUKIT \")\n",
        "    if \" ST\" == new_strt[-3:]:\n",
        "      new_strt = new_strt[:-3] + \" STREET\"\n",
        "    if \" RD\" == new_strt[-3:]:\n",
        "      new_strt = new_strt[:-3] + \" ROAD\"\n",
        "    if new_strt == \"JLN MEMBINA BARAT\":\n",
        "      new_strt = \"Central Green Condo\" #Road no longer exists\n",
        "    if \"JLN \" in new_strt:\n",
        "      new_strt = new_strt.replace(\"JLN \", \"JALAN \")\n",
        "    if \"LOR \" in new_strt:\n",
        "      new_strt = new_strt.replace(\"LOR \", \"LORONG \")\n",
        "    if \" AVE \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" AVE \", \" AVENUE \")\n",
        "    if \" AVE\" == new_strt[-4:]:\n",
        "      new_strt = new_strt[:-4] + \" AVENUE\"\n",
        "    if \" DR \" in new_strt:\n",
        "      new_strt = new_strt.replace(\" DR \", \" DRIVE \")\n",
        "    if \" DR\" == new_strt[-3:]:\n",
        "      new_strt = new_strt[:-3] + \" DRIVE\"\n",
        "    if \"C'WEALTH\" in new_strt:\n",
        "      new_strt = new_strt.replace(\"C'WEALTH\", \"COMMONWEALTH\")\n",
        "    if \"TG \" in new_strt:\n",
        "      new_strt = new_strt.replace(\"TG \", \"TANJONG \")\n",
        "    if new_strt == \"KG BAHRU HILL\":\n",
        "      new_strt = \"SPOONER ROAD\" #Road no longer exists\n",
        "    elif \"KG \" in new_strt:\n",
        "      new_strt = new_strt.replace(\"KG \", \"KAMPONG \")\n",
        "    if \"UPP \" in new_strt:\n",
        "      new_strt = new_strt.replace(\"UPP \", \"UPPER \")\n",
        "    if \"BUANGKOK SOUTH FARMWAY 1\" == new_strt:\n",
        "      new_strt = \"BUANGKOK\" #Road no longer exists\n",
        "\n",
        "    #If street not already in unique_streets, add it\n",
        "    if new_strt not in unique_streets:\n",
        "      unique_streets.append(new_strt)\n",
        "  return\n",
        "\n",
        "\n",
        "#Selects unique streets for processing, and stores streets for returning to initial dataset\n",
        "streets = []\n",
        "unique_streets = []\n",
        "preprocessing(data[1:], streets, unique_streets)\n",
        "print(\"Streets split\")\n",
        "\n",
        "#Converts each item in streets to a list in the format [street_name, latitude, longitude]\n",
        "i = 0\n",
        "for row in unique_streets:\n",
        "  address = row\n",
        "  lat, lon = get_lat_lon(address)\n",
        "  unique_streets[i] = [row, lat, lon]\n",
        "  i += 1\n",
        "print(\"Coordinates calculated\")\n",
        "\n",
        "# Initialized the values for CBD's latitude and longitude\n",
        "CBD = [1.2812, 103.8503]\n",
        "# Calculates distance to CBD of each location\n",
        "for row in unique_streets:\n",
        "  dist = haversine(CBD[0], CBD[1], row[1], row[2])\n",
        "  row.append(dist)\n",
        "print(\"Distance calculated\")\n",
        "\n",
        "# Adjusts main dataset to reflect dist to CBD instead of street name\n",
        "for row in data:\n",
        "  if streets.index(row[4]) > len(unique_streets):\n",
        "    print(\"Error\")\n",
        "    print(row[4]) #Preprocessing checks\n",
        "  else:\n",
        "    record = unique_streets[streets.index(row[4])]\n",
        "    row[4] = record[3]\n",
        "print('Data attached to current dataset')\n",
        "\n",
        "# Attached data to main working dataset\n",
        "for row in range(len(data)):\n",
        "  master[row].append(data[row][4])\n",
        "print(\"Data attached to main dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N75Ze-GrYwB",
        "outputId": "8b78cce3-4cca-41c4-c071-d57cb5e8a9fb"
      },
      "outputs": [],
      "source": [
        "#7 Insert population into dataset\n",
        "with open('Datasets/M810811.csv', 'r') as f:\n",
        "  finalliz = f.readlines()\n",
        "  year = (finalliz[10].strip().split(','))[1:] #removing irrelevant data and the header value to obtain the years\n",
        "  population = (finalliz[11].strip().split(','))[1:] #removing irrelevant data and the header value to obtain the gdp\n",
        "\n",
        "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
        "finalpop = []\n",
        "finalyear = []\n",
        "for row in year:\n",
        "  for m in months:\n",
        "    hold = row.strip()+m\n",
        "    if hold not in year:\n",
        "      finalyear.append(hold)\n",
        "\n",
        "for pop in population:\n",
        "  for i in range(12):\n",
        "    finalpop.append(pop)\n",
        "\n",
        "#adding the correct unemployment rate to the correct month in the dataset based on the float key of the month in finaldic\n",
        "for row in master:\n",
        "  for item in finalyear:\n",
        "    if row[month] == float(item):\n",
        "      row += [float(finalpop[finalyear.index(item)])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset = master[:596524] # 1990-2009\n",
        "valset = master[596524:709050] # 2010-2014\n",
        "testset = master[709050:810459] #2015-2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "#write to the storage dataset\n",
        "def writefile(dataset, index):\n",
        "    filesetname = [\"19902009processedtesting\", \"20102014processedvalidation\", \"20152019processedtesting\"]\n",
        "    with open(\"Datasets/\" + filesetname[index] + \".csv\", \"w\") as f:\n",
        "        for row in master:\n",
        "            i = 0\n",
        "            if len(row) == 10: #Checks for incomplete data. Print tests show data with wrong length is minimal enough to ignore altogether\n",
        "                for each in row:\n",
        "                    if type(each) != str:\n",
        "                        each = str(each)\n",
        "                    f.write(each)\n",
        "                    i += 1\n",
        "                    if i < 10:\n",
        "                        f.write(\",\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "writefile(trainset, 0)\n",
        "writefile(valset, 1)\n",
        "writefile(testset, 2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
